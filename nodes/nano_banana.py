# -*- coding: utf-8 -*-
"""Nano Banana å›¾åƒèŠ‚ç‚¹ - ä»¿ç…§ ComfyUI å®˜æ–¹ Google Gemini å›¾åƒèŠ‚ç‚¹"""

import torch
import os
import random
from typing import Tuple

try:
    from ..utils.api_client import GeminiAPIClient, GeminiAPIError
    from ..utils.image_utils import tensor_to_pil, pil_to_tensor, pil_to_base64, bytes_to_pil, create_empty_image
    from ..utils.file_utils import read_file_as_base64, get_mime_type
except ImportError:
    import sys
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from utils.api_client import GeminiAPIClient, GeminiAPIError
    from utils.image_utils import tensor_to_pil, pil_to_tensor, pil_to_base64, bytes_to_pil, create_empty_image
    from utils.file_utils import read_file_as_base64, get_mime_type

DEFAULT_SYSTEM_PROMPT = """You are an expert image generation engine. You must ALWAYS produce an image.
Interpret all user inputâ€”regardless of format, intent, or abstractionâ€”as literal visual directives for image composition.
If a prompt is conversational or lacks specific visual details, you must creatively invent a concrete visual scenario that depicts the concept.
Prioritize generating the visual representation above any text, formatting, or conversational requests."""

REVERSE_PROMPT_SYSTEM = """You are an expert at analyzing images and generating detailed prompts for AI image generation.
When given an image, provide a comprehensive description that can be used to recreate similar images.
Include details about: subject, composition, lighting, colors, style, mood, and technical aspects."""

CATEGORY_PREFIX = "ðŸ”ºCCUT_LK"


class LK_NanoBanana:
    """ðŸŒ LK Nano Banana (Google Gemini å›¾åƒ) - gemini-2.5-flash-image"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {"required": {
            "prompt": ("STRING", {"multiline": True, "placeholder": "è¾“å…¥å›¾åƒç”Ÿæˆæç¤ºè¯...", "dynamicPrompts": True}),
            "model": (["gemini-2.5-flash-image", "gemini-2.5-flash-preview-image"], {"default": "gemini-2.5-flash-image"}),
            "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
            "seed_control": (["randomize", "increment", "fixed"], {"default": "randomize"}),
            "aspect_ratio": (["auto", "1:1", "16:9", "9:16", "4:3", "3:4", "3:2", "2:3"], {"default": "auto"}),
            "response_modalities": (["IMAGE+TEXT", "IMAGE_ONLY"], {"default": "IMAGE+TEXT"}),
            "api_key": ("STRING", {"default": "", "placeholder": "è¾“å…¥ Gemini API å¯†é’¥"})
        }, "optional": {
            "image": ("IMAGE",),
            "file": ("STRING", {"forceInput": True}),
            "system_prompt": ("STRING", {"multiline": True, "default": DEFAULT_SYSTEM_PROMPT})
        }}
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("å›¾åƒ", "æ–‡æœ¬")
    FUNCTION = "generate"
    CATEGORY = f"{CATEGORY_PREFIX}/Gemini/NanoBanana"

    def generate(self, prompt, model, seed, seed_control, aspect_ratio, response_modalities, api_key,
                 image=None, file=None, system_prompt=None):
        if not api_key: return (create_empty_image(), "é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„ API å¯†é’¥")
        actual_seed = random.randint(0, 0xffffffffffffffff) if seed_control == "randomize" else (seed + 1 if seed_control == "increment" else seed)
        try:
            client = GeminiAPIClient(api_key, timeout=120)
            parts = []
            if image is not None:
                parts.append({"inlineData": {"mimeType": "image/png", "data": pil_to_base64(tensor_to_pil(image))}})
            if file and os.path.exists(file):
                b64 = read_file_as_base64(file)
                if b64: parts.append({"inlineData": {"mimeType": get_mime_type(file), "data": b64}})
            parts.append({"text": prompt})
            modalities = ["Image"] if response_modalities == "IMAGE_ONLY" else ["Text", "Image"]
            img_config = {"aspectRatio": aspect_ratio} if aspect_ratio != "auto" else {}
            response = client.generate_content(model=model, contents=[{"parts": parts}],
                system_instruction=system_prompt or DEFAULT_SYSTEM_PROMPT, response_modalities=modalities,
                image_config=img_config if img_config else None)
            images = client.parse_image_response(response)
            text = client.parse_text_response(response)
            if images: return (pil_to_tensor(bytes_to_pil(images[0])), text or f"ç”ŸæˆæˆåŠŸ (seed: {actual_seed})")
            return (create_empty_image(), text or "æœªèƒ½ç”Ÿæˆå›¾åƒ")
        except GeminiAPIError as e: return (create_empty_image(), f"API é”™è¯¯: {str(e)}")
        except Exception as e: return (create_empty_image(), f"é”™è¯¯: {str(e)}")


class LK_NanoBananaPro:
    """ðŸŒ LK Nano Banana Pro (Google Gemini å›¾åƒ) - gemini-3-pro-image-preview é«˜è´¨é‡"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {"required": {
            "prompt": ("STRING", {"multiline": True, "placeholder": "è¾“å…¥å›¾åƒç”Ÿæˆæç¤ºè¯...", "dynamicPrompts": True}),
            "model": (["gemini-3-pro-image-preview", "gemini-2.5-pro-image"], {"default": "gemini-3-pro-image-preview"}),
            "seed": ("INT", {"default": 12345, "min": 0, "max": 0xffffffffffffffff}),
            "seed_control": (["fixed", "randomize", "increment"], {"default": "fixed"}),
            "aspect_ratio": (["16:9", "9:16", "1:1", "4:3", "3:4", "3:2", "2:3"], {"default": "16:9"}),
            "resolution": (["1K", "2K", "4K"], {"default": "2K"}),
            "response_modalities": (["IMAGE+TEXT", "IMAGE_ONLY"], {"default": "IMAGE+TEXT"}),
            "api_key": ("STRING", {"default": "", "placeholder": "è¾“å…¥ Gemini API å¯†é’¥"})
        }, "optional": {
            "image": ("IMAGE",),
            "file": ("STRING", {"forceInput": True}),
            "system_prompt": ("STRING", {"multiline": True, "default": DEFAULT_SYSTEM_PROMPT})
        }}
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("å›¾åƒ", "æ–‡æœ¬")
    FUNCTION = "generate"
    CATEGORY = f"{CATEGORY_PREFIX}/Gemini/NanoBanana"

    def generate(self, prompt, model, seed, seed_control, aspect_ratio, resolution, response_modalities, api_key,
                 image=None, file=None, system_prompt=None):
        if not api_key: return (create_empty_image(), "é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„ API å¯†é’¥")
        actual_seed = random.randint(0, 0xffffffffffffffff) if seed_control == "randomize" else (seed + 1 if seed_control == "increment" else seed)
        try:
            client = GeminiAPIClient(api_key, timeout=180)
            parts = []
            if image is not None:
                parts.append({"inlineData": {"mimeType": "image/png", "data": pil_to_base64(tensor_to_pil(image))}})
            if file and os.path.exists(file):
                b64 = read_file_as_base64(file)
                if b64: parts.append({"inlineData": {"mimeType": get_mime_type(file), "data": b64}})
            parts.append({"text": prompt})
            modalities = ["Image"] if response_modalities == "IMAGE_ONLY" else ["Text", "Image"]
            img_config = {"aspectRatio": aspect_ratio, "imageSize": resolution}
            response = client.generate_content(model=model, contents=[{"parts": parts}],
                system_instruction=system_prompt or DEFAULT_SYSTEM_PROMPT, response_modalities=modalities,
                image_config=img_config)
            images = client.parse_image_response(response)
            text = client.parse_text_response(response)
            if images: return (pil_to_tensor(bytes_to_pil(images[0])), text or f"ç”ŸæˆæˆåŠŸ (seed: {actual_seed}, {resolution})")
            return (create_empty_image(), text or "æœªèƒ½ç”Ÿæˆå›¾åƒ")
        except GeminiAPIError as e: return (create_empty_image(), f"API é”™è¯¯: {str(e)}")
        except Exception as e: return (create_empty_image(), f"é”™è¯¯: {str(e)}")


class LK_ImageToPrompt:
    """ðŸ”„ LK å›¾åƒåæŽ¨æç¤ºè¯ - åˆ†æžå›¾åƒç”Ÿæˆè¯¦ç»†æç¤ºè¯"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {"required": {
            "image": ("IMAGE",),
            "model": (["gemini-2.5-flash", "gemini-2.5-pro", "gemini-3-flash-preview", "gemini-1.5-flash"], {"default": "gemini-2.5-flash"}),
            "output_format": (["SD/FLUX æç¤ºè¯", "Midjourney æç¤ºè¯", "è¯¦ç»†æè¿°", "ç®€çŸ­æè¿°", "æ ‡ç­¾åˆ—è¡¨"], {"default": "SD/FLUX æç¤ºè¯"}),
            "language": (["English", "ä¸­æ–‡", "åŒè¯­ (Bilingual)"], {"default": "English"}),
            "api_key": ("STRING", {"default": "", "placeholder": "è¾“å…¥ Gemini API å¯†é’¥"})
        }, "optional": {
            "file": ("STRING", {"forceInput": True}),
            "additional_instructions": ("STRING", {"multiline": True, "placeholder": "é¢å¤–æŒ‡ä»¤ï¼ˆå¯é€‰ï¼‰...", "default": ""})
        }}
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("æ­£å‘æç¤ºè¯", "è´Ÿå‘æç¤ºè¯")
    FUNCTION = "analyze"
    CATEGORY = f"{CATEGORY_PREFIX}/Gemini/NanoBanana"

    def analyze(self, image, model, output_format, language, api_key, file=None, additional_instructions=""):
        if not api_key: return ("é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„ API å¯†é’¥", "")
        try:
            client = GeminiAPIClient(api_key, timeout=60)
            parts = []
            if image is not None:
                parts.append({"inlineData": {"mimeType": "image/png", "data": pil_to_base64(tensor_to_pil(image))}})
            if file and os.path.exists(file):
                b64 = read_file_as_base64(file)
                if b64: parts.append({"inlineData": {"mimeType": get_mime_type(file), "data": b64}})
            
            format_map = {"SD/FLUX æç¤ºè¯": "SD/FLUX format: comma-separated tags", "Midjourney æç¤ºè¯": "Midjourney format with --ar hints",
                "è¯¦ç»†æè¿°": "Comprehensive paragraph description", "ç®€çŸ­æè¿°": "Brief one-paragraph summary", "æ ‡ç­¾åˆ—è¡¨": "Comma-separated keywords"}
            lang_map = {"English": "English only", "ä¸­æ–‡": "ä¸­æ–‡", "åŒè¯­ (Bilingual)": "English and Chinese"}
            
            prompt = f"""Analyze this image and generate a prompt to recreate it.
Format: {format_map.get(output_format, '')}
Language: {lang_map.get(language, '')}
{f'Additional: {additional_instructions}' if additional_instructions else ''}
Output JSON: {{"positive_prompt": "...", "negative_prompt": "..."}}"""
            parts.append({"text": prompt})
            
            response = client.generate_content(model=model, contents=[{"parts": parts}], system_instruction=REVERSE_PROMPT_SYSTEM)
            result = client.parse_text_response(response)
            try:
                import json
                start, end = result.find("{"), result.rfind("}") + 1
                if start != -1 and end > start:
                    parsed = json.loads(result[start:end])
                    return (parsed.get("positive_prompt", result), parsed.get("negative_prompt", ""))
            except: pass
            return (result, "")
        except GeminiAPIError as e: return (f"API é”™è¯¯: {str(e)}", "")
        except Exception as e: return (f"é”™è¯¯: {str(e)}", "")
